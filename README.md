# Project Description
Final project of the Introduction to Machine Learning subject.

The objective of the final project was to develop various classifiers using different machine learning algorithms. The explored options included K-Nearest Neighbors, Random Forest, Logistic Regression, Decision Trees, Bayesian Classifier, and Support Vector Machine. the dataset was dividedin two parts: 80% for training and 20% for validation. Hyperparameter tuning was conducted by exploring a range of values and performing cross-validation for each combination. The optimal hyperparameters were then selected based on performance metrics and tested on the validation split.

Subsequently, the K-Nearest Neighbors (KNN) algorithm was chosen for further experimentation. This involved implementing dimensionality reduction techniques such as Condensed Nearest Neighbor (CNN) rule and Principal Component Analysis (PCA) to reduce the dataset's complexity. A comparative analysis between the performance of KNN on the original and reduced datasets was conducted.

Additionally, artificial imbalance was introduced into the dataset to simulate real-world scenarios with varying class ratios. A new KNN algorithm was trained on the imbalanced dataset, and its performance was compared against the original balanced dataset.

## Files
This project contains three files:
- Report.pdf: A LaTeX-generated report detailing the project methodology and findings.
- Unified code.ipynb: Jupyter Notebook containing the project's code implementation.
- Waveform.data: Datase used for the project.

## Authors
- Alejandro Carvajal
- Uggo Labb√©


